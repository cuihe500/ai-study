---
## sidebar_position: 2
---

# 认识主流大模型

## 本章要点

在这一章，我将带你认识当今AI舞台上的"主角们"——那些你每天都在听说名字的大语言模型。你将了解国际三大模型家族（OpenAI的GPT系列、Anthropic的Claude、Google的Gemini）各自的特点和优势，也会认识中国本土崛起的一批优秀模型（通义千问、文心一言、智谱GLM、DeepSeek、Kimi、豆包等）。更重要的是，我将帮助你建立对不同模型能力的直觉判断，为后续选择工具打下基础。

## 为什么要了解这些模型？

你可能会问：我只想用AI来帮我写代码，为什么要花时间去了解这些模型的不同？这不是多此一举吗？

这让我想起买车的故事。当你决定买一辆车的时候，你大概不会随便走进一家4S店，指着展厅里的第一辆车说"就它了"。你会考虑：这辆车是轿车还是SUV？动力够不够？油耗怎么样？适合长途还是短途？质量问题多不多？保值率如何？这些问题的答案会影响你的选择，而你的选择又会影响你之后几年的用车体验。

选择一个AI模型，道理也是一样的。不同的模型有不同的"性格"和"特长"。有的模型擅长写代码，有的模型更会写文章；有的模型回答简洁直接，有的模型喜欢详细解释；有的模型中文能力出色，有的模型英文表达更精准。如果你不知道这些差异，很可能会在一个不适合你需求的模型上浪费时间，甚至得出"AI不行"的错误结论。

更重要的是，你在下一章将会学到，不同的AI编程工具往往绑定不同的底层模型。Cursor可以选择使用Claude还是GPT；GitHub Copilot底层是GPT系列；而国产的编程助手可能使用的是自家的模型。了解模型的差异，能帮你在选择工具时做出更明智的决定。

所以，让我们花点时间，好好认识一下这些"AI时代的主角"。

## 国际主流大模型

### OpenAI：GPT系列

说到大语言模型，OpenAI的GPT系列无疑是绕不开的名字。它就像AI领域的"iPhone"——不一定是技术上最领先的，但绝对是最有影响力的。

**GPT系列的发展脉络**我们在上一章已经聊过：从GPT-1到GPT-3再到GPT-4，规模越来越大，能力越来越强。进入2025-2026年，OpenAI已经推出了**GPT-5.2/GPT-5.3 Codex**系列，以及专门的推理模型**o3/o4系列**。GPT-5.3 Codex在代码生成能力上有了质的飞跃，成为当前最强大的编程辅助模型之一。

**GPT模型的特点是"全面"。** 这不是一句空话。GPT-5系列在代码生成、数学推理、创意写作、知识问答、多语言处理等多个维度上都有着相当均衡的表现。它就像一个十八般武艺样样通晓的武林高手，你让它写代码、写文章、翻译、做数学题，它都能给你一个还不错的答案。这种"全面"使得它成为很多AI编程工具的默认选择。

**另一个特点是"听话"。** GPT系列对指令的响应非常积极，你让它做什么，它就做什么，很少和你"讨价还价"。这种特性在编程场景中很实用——你给出明确的需求描述，它就按你的意思来。但有时候这也是一把双刃剑：它可能过于配合，即使你的需求本身有问题也会顺着你的意思来，而不是提醒你重新考虑。

**在编程领域**，GPT-5.3 Codex是目前综合表现最好的模型之一。它能理解复杂的代码结构，生成符合最佳实践的代码，在多种编程语言上都有出色的表现。GitHub Copilot就是基于GPT系列的模型构建的，你会在后续章节深入了解它。

当然，GPT也有它的短板。它的中文能力虽然不断在提升，但和顶尖的国产模型相比还有差距。另外，OpenAI的服务在中国大陆无法直接访问，这对很多开发者来说是一个实际的障碍。

### Anthropic：Claude系列

如果说GPT是AI领域的"iPhone"，那么Claude可能就是"Pixel"——不那么大众，但有一群非常忠诚的用户，在特定领域有着令人惊叹的表现。

**Claude最大的特点是"长上下文"。** 什么是上下文？简单来说，就是模型能"记住"多少内容。2026年初，Claude Opus 4.6和Claude Sonnet 4.6已经支持高达**100万token的上下文窗口**，这意味着你可以把整本书、整个大型项目的代码全部塞给它，它都能记住、理解、回应。这个能力在编程场景中特别有用：你可以把整个代码库发给它，让它理解项目结构后再给出建议，而不是只能看一个孤立的文件。

**Claude的第二个特点是"谨慎"。** 相比GPT的"听话"，Claude更愿意表达不同意见。如果你提出的请求可能带来问题，Claude往往会指出潜在的风险，而不是盲目执行。这种特性使得它在代码审查、安全分析等场景中特别有价值。

**在编程能力方面**，Claude的表现相当出色。很多资深程序员反馈，Claude在理解复杂代码逻辑、重构建议、架构设计讨论等方面尤其突出。它生成的代码往往更加规范，注释也更详细。这本书正是使用Claude Code来编写的——你可以亲自体验一下它的能力。

**Claude还有一个独特之处：它更"诚实"。** 当它不知道某个问题的答案时，它更可能直接说"我不确定"，而不是编造一个看起来很像真的答案。这种"承认无知的勇气"在AI领域是非常稀缺的品质，能帮你避免被"一本正经地胡说八道"所误导。

### Google：Gemini系列

Google在大模型领域的入局稍晚，但Gemini的出现让这场竞争变得更加精彩。2026年初，Google已经推出了**Gemini 3 Pro**和**Gemini 3.1 Pro**，后者在推理性能上较前代提升逾两倍。

**Gemini的独特之处在于"原生多模态"。** 什么是多模态？就是模型能同时理解文字、图片、音频、视频等多种类型的信息。Gemini从设计之初就是多模态的。这意味着它在处理图文混合的任务时有着天然的优势。

**与Google生态的深度整合**是Gemini的另一大优势。如果你经常使用Google的服务（Gmail、Google Docs、Google Sheets等），Gemini能帮你自动总结邮件、生成文档、分析表格。这种"无缝融入工作流"的体验，是其他模型难以企及的。

**在编程方面**，Gemini的表现正在快速追赶。Gemini 3.1 Pro在核心推理测试中表现优异，在HLE（Humanity's Last Exam）测试中超越了GPT-5.2。如果你使用Google Cloud进行开发，Gemini可能是最方便的选择。

**Gemini的另一个特点是"更新频繁"。** Google给它取名Gemini（双子座），似乎暗示它的"两面性"——一方面有强大的能力，另一方面也在不断变化和进化。

### 其他值得关注的国际模型

除了这三大巨头，还有一些模型值得关注：

**Meta的Llama系列**是开源领域的"明星"。它的最大特点是**开源**——你可以在自己的服务器上运行它，不需要把数据发送给任何第三方。这对于有数据隐私要求的企业和项目来说非常有价值。虽然性能上略逊于闭源模型，但它的存在推动了整个开源模型生态的发展。

**Mistral**是一家法国AI公司推出的模型，以"小而美"著称。它的模型参数量不大，但在很多任务上的表现却不输给大模型。如果你追求在本地运行、低延迟的体验，Mistral是一个值得考虑的选择。

## 国内主流大模型

如果说国际大模型是"世界级选手"，那么国内大模型就是"主场作战的精锐"。它们在中文理解、本土服务、合规性等方面有着天然的优势。2026年初，国产大模型实现了历史性突破——根据OpenRouter数据，2026年2月中国AI模型调用量首次超越美国，在全球调用量前五的模型中占据四席。

### 阿里巴巴：通义千问

通义千问（Qwen）是阿里巴巴推出的大语言模型，也是国内综合实力最强的模型之一。

**通义千问在编程领域表现突出。** Qwen3及Qwen3.5系列专门针对代码生成进行了优化，在多项代码能力评测中表现不俗。2026年2月，阿里开源了**Qwen3.5-397B-A17B**和**Qwen3.5-27B**等中等规模模型，创下中等尺寸模型的性能新高。更难得的是，通义千问对中文编程需求的理解非常到位——你用中文描述需求，它能准确理解你的意图，而不是简单地翻译成英文再处理。

**开源生态是通义千问的一大优势。** 阿里将多个版本的模型开源，这使得开发者可以在自己的环境中部署和微调。如果你对数据隐私有要求，或者想要一个可以深度定制的模型，通义千问是一个很好的起点。目前Qwen3已支持**100万tokens的超长上下文**。

**与阿里云生态的整合**也是它的一大卖点。如果你的项目已经部署在阿里云上，通义千问可以无缝集成到你的开发流程中，从需求分析到代码生成到部署上线，一站式解决。

### 百度：文心一言

文心一言（ERNIE）是百度推出的大语言模型，也是国内最早面向公众开放的大模型之一。

**文心一言的强项在于"知识和应用"。** 百度多年的搜索经验和知识图谱积累，为文心一言提供了丰富的中文知识储备。当你问它关于中国文化、历史、法律、商业等方面的问题时，它的回答往往比国际模型更准确、更符合中国国情。2025-2026年，文心一言已**全面免费**，大大降低了使用门槛。

**在编程领域**，文心一言的表现也在持续进步。它对中文技术文档的理解尤其出色，能够基于中文官方文档给出准确的代码建议。如果你主要使用中文技术资料学习编程，文心一言可能是一个不错的帮手。

**千帆平台**为开发者提供了便捷的接入方式。你可以在百度的AI开发平台上快速体验和集成文心一言的能力，无需复杂的配置。

### 智谱AI：GLM系列

智谱AI是一家技术实力雄厚的公司，其GLM系列模型在学术界和开发者社区中享有很高的声誉。

**GLM的特长在于"学术与技术深度"。** 智谱AI源自清华大学的技术团队，其模型在复杂推理、技术问答等方面表现出色。2026年2月发布的**GLM-5**在代码能力上对齐Claude Sonnet 4，在复杂系统工程和Agent任务规划上展现出接近国际顶尖闭源模型的能力。

**GLM-5支持200K超长上下文窗口**，能够处理较长的文档和代码。如果你是研究人员或者想要深入研究大模型技术，智谱的开源模型是很好的学习材料。

**开源和商业化并重**是智谱的策略。它既提供商业API服务，也开源了多个版本的模型，在Agent工作流方面表现尤为突出。

### 月之暗面：Kimi

Kimi是月之暗面推出的大语言模型，因其出色的长文本处理能力而走红。

**Kimi最让人印象深刻的是它的"长文本"和"Agent能力"。** 2025-2026年，Kimi K2和**Kimi K2.5**相继发布，K2.5采用**1.5万亿参数的MoE架构**，首创"Agent Swarm"架构，可自主调度**100个子智能体并行协作**。你可以把整本书、一大堆论文、整个项目的文档发给它，它能准确理解其中的内容，并进行总结、回答问题、提取关键信息。

**Kimi的"聪明"还体现在信息整合上。** 它可以联网搜索，将搜索到的多篇资料整合起来回答你的问题。当你需要了解一个新技术、调研一个方案的可行性时，Kimi能帮你快速收集和整理信息。

**在编程辅助方面**，Kimi在SWE-bench Verified测试中取得65.8%的得分，仅次于Claude Sonnet 4。你可以把一段复杂的代码发给它，让它解释每一步在做什么；你也可以把多个文件的代码发过去，让它帮你理解整个项目的架构。它就像一个耐心的导师，陪你一起阅读和分析代码。

### DeepSeek

DeepSeek是一家相对新锐但发展神速的AI公司，其模型在编程领域的表现尤其亮眼。

**DeepSeek-V3.2和DeepSeek-R1是专门为编程和推理打造的模型。** 在HumanEval和各大数学竞赛榜单上，DeepSeek-V3.2的表现直逼甚至超越GPT-4。在LiveCodeBench等编程测试中，DeepSeek经常领跑所有模型。如果你主要关心"AI帮我写代码"这件事，DeepSeek值得你重点关注。

**开源策略非常慷慨。** DeepSeek将多个版本的模型开源，包括V3、R1等，这些模型可以在本地运行，对于追求数据隐私的开发者来说是福音。

**性价比极高。** DeepSeek的API服务价格极其便宜（几乎是"白菜价"），对于预算有限的个人开发者或小团队来说，是一个吸引力十足的选择。2026年2月，DeepSeek V3.2在全球调用量排名中跻身前五。

### 字节跳动：豆包

豆包是字节跳动推出的AI助手，定位更加"亲民"，在日常生活和创意场景中表现出色。

**豆包大模型2.0（Seed 2.0）在2026年2月发布**，Pro版性能全面对标GPT-5.2，原生支持**视频流实时分析**，在EgoTempo基准测试中首次超越人类平均分。它的多模态能力和对中文语境的细腻把握，使其在情感类文案和创意发散上优势明显。

**豆包的特点在于"流畅自然"。** 写短视频脚本、社交媒体文案或进行拟人化闲聊，豆包的体验最为流畅。日均tokens使用量暴增137倍，足见其受欢迎程度。

**与字节生态的整合**也是一大优势。如果你使用抖音、飞书等产品，豆包可以无缝接入你的工作流。

### MiniMax

MiniMax是2026年初崛起的新星，其**M2.5模型**上线不足一周便登顶全球API调用量榜首，单模型贡献1.44万亿Token增量。

**M2.5的特点在于"高效与实用"。** 它在编程类测试中刷新行业纪录，同时大幅提升了成本效益。对于追求性价比的开发者来说，MiniMax是一个值得关注的新选择。

### 其他国内模型

国内大模型的生态非常丰富，除了上面介绍的几家，还有许多值得关注的选择：

**腾讯的混元**与腾讯云生态深度整合，在处理群聊摘要、公众号文章提炼等社交场景任务上颇具特色。

**华为的盘古**专注于企业级场景，在工业、金融、政务等领域有深度优化，依托昇腾芯片构建全栈国产算力方案。

**百川智能的Baichuan系列**同样是开源领域的积极贡献者，支持多种参数量级的模型选择。

## 不同模型的能力对比

说了这么多，你可能想知道：如果我主要关心AI辅助编程，应该怎么选择？让我用一个表格来帮你快速比较：

| 模型              | 编程能力  | 中文理解  | 长文本处理 | 开源可用 | 国内直达访问 | 最新版本                             |
| --------------- | ----- | ----- | ----- | ---- | ------ | -------------------------------- |
| GPT-5.3 Codex   | ★★★★★ | ★★★☆☆ | ★★★★☆ | 否    | 否      | GPT-5.3 Codex (2026.02)          |
| Claude Opus 4.6 | ★★★★★ | ★★★☆☆ | ★★★★★ | 否    | 需要代理   | Claude Opus/Sonnet 4.6 (2026.02) |
| Gemini 3.1 Pro  | ★★★★★ | ★★★☆☆ | ★★★★☆ | 否    | 需要代理   | Gemini 3.1 Pro (2026.02)         |
| 通义千问            | ★★★★★ | ★★★★★ | ★★★★★ | 是    | 是      | Qwen3.5系列 (2026.02)              |
| 文心一言            | ★★★★☆ | ★★★★★ | ★★★★☆ | 否    | 是      | 全面免费版 (2026)                     |
| GLM-5           | ★★★★★ | ★★★★☆ | ★★★★★ | 是    | 是      | GLM-5 (2026.02)                  |
| Kimi K2.5       | ★★★★★ | ★★★★★ | ★★★★★ | 否    | 是      | Kimi K2.5 (2026.02)              |
| DeepSeek        | ★★★★★ | ★★★★☆ | ★★★★☆ | 是    | 是      | DeepSeek-V3.2/R1 (2026)          |
| 豆包2.0           | ★★★★☆ | ★★★★★ | ★★★★☆ | 否    | 是      | Seed 2.0 (2026.02)               |
| MiniMax M2.5    | ★★★★★ | ★★★★☆ | ★★★★☆ | 否    | 是      | M2.5 (2026.02)                   |

*注：以上评价基于2026年初的情况，模型能力在不断迭代，请以最新情况为准。*

## 如何选择适合你的模型？

面对这么多选择，你可能会感到眼花缭乱。让我给你一个简单的决策框架：

**如果你在中国大陆**，优先考虑国内模型。主要原因有三个：访问更方便（不需要代理）、中文理解更好、价格往往更低。通义千问、DeepSeek和GLM-5在编程方面表现突出，是不错的起点。2026年初，国产模型在全球范围内的竞争力已大幅提升，MiniMax M2.5、Kimi K2.5、GLM-5和DeepSeek V3.2甚至霸榜全球API调用量前五。

**如果你追求最强的编程能力**，GPT-5.3 Codex、Claude Opus 4.6、DeepSeek-V3.2和GLM-5是当前最有竞争力的选择。很多AI编程工具（如Cursor）都支持多个模型，你可以根据实际体验来选择。

**如果你需要分析很长的文档或代码库**，Claude（支持100万token上下文）和通义千问/Qwen3（支持100万tokens上下文）是最好的选择，它们的长上下文能力能帮你处理整本书或整个项目。

**如果你有数据隐私要求**，考虑开源模型。通义千问、DeepSeek、GLM都有开源版本，你可以在自己的服务器上运行，数据完全掌控在自己手中。

**如果你是初学者**，我建议从Kimi或通义千问开始。它们的中文能力出色，理解你的需求几乎没有障碍，上手门槛较低。

**如果你需要Agent能力**，Kimi K2.5的"Agent Swarm"架构可以调度100个子智能体并行协作，GLM-5在复杂系统工程和Agent任务规划上也表现优异。

## 一个实用的建议

最后，我想给你一个实用的建议：**不要"从一而终"。**

不同的模型有不同的强项。你现在用Claude来帮你写代码，之后可能会发现Kimi更适合帮你读文档，再之后可能发现DeepSeek在某些任务上性价比更高，或者发现GLM-5在Agent工作流中表现更出色。这不是"背叛"，而是"人尽其才"。

如果你问我怎么做的：我在写代码时会切换使用Claude、GPT-5和DeepSeek，因为它们各有千秋；在查阅资料时会用Kimi或通义千问，因为它们能读很长的文档；在需要本地处理敏感数据时会用开源的DeepSeek或Qwen；在需要复杂Agent任务时会用GLM-5或Kimi K2.5。这就像一个木匠的工箱里有多种工具——锤子、锯子、刨子，各有用途，根据场景选择最合适的那个。

## 小结

这一章，我们一起走马观花地认识了当今AI领域的"主角们"。

在国际舞台上，我们看到了"全面均衡"的GPT-5.3 Codex、"长上下文高手"Claude 4.6、"推理性能翻倍"的Gemini 3.1 Pro，以及它们各自的特点。在国际模型的选择上，你需要在能力、访问便利性、价格之间找到平衡点。

在国内舞台上，我们认识了"编程强手"通义千问/Qwen3.5、"知识渊博且全面免费"的文心一言、"Agent能力顶尖"的GLM-5、"长文本与Agent专家"Kimi K2.5、"代码新星与性价比之王"DeepSeek-V3.2、"多模态创意助手"豆包2.0，以及"全球调用量冠军"MiniMax M2.5。国内模型在中文理解、本土服务、合规性方面有着天然的优势，而且访问更方便。2026年初，国产大模型已经实现了从"跟跑"到"并跑"甚至部分"领跑"的历史性跨越。

这些模型就像是AI世界里的"诸子百家"，各有主张，各有侧重。作为使用者，你不必"择一而从"，而是应该了解它们的特点，根据不同的场景选择最合适的工具。

下一章，我们将从"认识模型"走向"认识工具"——我将带你了解当前主流的AI编码工具，那些你日常工作中真正会用到的东西。

## 练习

**实践题**：选择两三个你还没用过的模型，亲自体验一下。问它们同样的编程问题，比如"请用Python写一个函数来找出列表中的最大值，并解释每一行代码"。比较一下它们的回答：谁写得更好？谁解释得更清楚？谁更让你觉得"听得懂"？可以尝试对比DeepSeek-V3.2、GLM-5和Claude Sonnet 4.6在代码生成上的差异。

**思考题**：回顾你过去使用AI的经历（如果有的话），你现在知道它们背后是什么模型了吗？2026年初国产大模型已经霸榜全球调用量前五，这个了解是否改变了你对国产模型的看法？如果让你重新选择，你会选哪个模型？

**拓展题**：如果你有条件，尝试一下不同模型处理长文本和Agent任务的能力。找一个较长的技术文档或代码文件，分别发给Claude 4.6、Kimi K2.5和通义千问Qwen3.5，让它们总结内容或解释代码。另外，尝试用GLM-5或Kimi K2.5完成一个需要多步骤协作的复杂任务，体验Agent能力的差异。看看谁能更好地处理长内容，谁在Agent协作上表现更出色。